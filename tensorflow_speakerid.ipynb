{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP46iIN+ZBCvrr/+Tk8InG1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speaker Identification"
      ],
      "metadata": {
        "id": "lR2Rvs6NVAuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow==2.8.0\n",
        "!pip3 install tensorflow-io==0.25.0"
      ],
      "metadata": {
        "id": "U3U7NbTCXS6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwG9JJB6U3OF",
        "outputId": "83063aea-44bc-4c0b-f2be-c88779cde192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n",
            "TensorFlow IO version: 0.25.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"TensorFlow IO version:\", tfio.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ROOT_DIR='/content/drive/MyDrive/College/Research/Linh_2023_Research'\n",
        "\n",
        "DATASET_PATH=ROOT_DIR+'/test_data/vox'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x6YLgMwXYmD",
        "outputId": "a0ae92ce-b3de-4fcf-b2a4-4e5f22ff59f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation\n",
        "[Keras Speaker Recognition](https://keras.io/examples/audio/speaker_recognition_using_cnn/)"
      ],
      "metadata": {
        "id": "OsF8O-L0VRZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLING_RATE = 16000\n",
        "N_MFCC = 13\n",
        "BATCH_SIZE = 128\n",
        "SHUFFLE_SEED = 43\n",
        "TRAIN_VALID_SPLIT = 0.2\n",
        "EPOCHS = 100\n",
        "\n",
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n",
        "    return audio\n",
        "\n",
        "def audio_to_fft(audio):\n",
        "    # # Since tf.signal.fft applies FFT on the innermost dimension,\n",
        "    # # we need to squeeze the dimensions and then expand them again\n",
        "    # # after FFT\n",
        "    # print(type(audio))\n",
        "    # audio = tf.squeeze(audio, axis=-1)\n",
        "    # fft = tf.signal.fft(\n",
        "    #     tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
        "    # )\n",
        "    # fft = tf.expand_dims(fft, axis=-1)\n",
        "\n",
        "    # # Return the absolute value of the first half of the FFT\n",
        "    # # which represents the positive frequencies\n",
        "    # return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])\n",
        "\n",
        "    # Convert the audio to MFCC\n",
        "    stfts = tf.signal.stft(audio, frame_length=1024, frame_step=256, fft_length=1024)\n",
        "    spectrograms = tf.abs(stfts)\n",
        "\n",
        "    # Warp the linear scale spectrograms into the mel-scale\n",
        "    num_spectrogram_bins = stfts.shape[-1]\n",
        "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, N_MFCC\n",
        "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "        num_mel_bins, num_spectrogram_bins, SAMPLING_RATE, lower_edge_hertz, upper_edge_hertz)\n",
        "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
        "    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "    # Compute a stabilized log to get log-magnitude mel-scale spectrograms\n",
        "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
        "\n",
        "    # Compute MFCCs from log_mel_spectrograms and take the first num_mfcc\n",
        "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :N_MFCC]\n",
        "\n",
        "    # Add an extra dimension to match the shape of the original code\n",
        "    mfccs = tf.expand_dims(mfccs, axis=-1)\n",
        "\n",
        "    return tf.math.abs(mfccs[:, : (audio.shape[1] // 2), :])"
      ],
      "metadata": {
        "id": "CXc8U7QY8Jwn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = os.listdir(DATASET_PATH)\n",
        "audio_paths = []\n",
        "labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    if label > 4: break\n",
        "    print(\"Processing speaker {}\".format(name,))\n",
        "    dir_path = Path(DATASET_PATH) / name\n",
        "    speaker_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    audio_paths += speaker_sample_paths\n",
        "    labels += [label] * len(speaker_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
        ")\n",
        "\n",
        "# Shuffle\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(audio_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Split into training and validation\n",
        "num_val_samples = int(TRAIN_VALID_SPLIT * len(audio_paths))\n",
        "print(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\n",
        "train_audio_paths = audio_paths[:-num_val_samples]\n",
        "train_labels = labels[:-num_val_samples]\n",
        "\n",
        "print(\"Using {} files for validation.\".format(num_val_samples))\n",
        "valid_audio_paths = audio_paths[-num_val_samples:]\n",
        "valid_labels = labels[-num_val_samples:]\n",
        "\n",
        "# Create 2 datasets, one for training and the other for validation\n",
        "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
        "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
        "\n",
        "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "valid_ds = valid_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSzqjnpz4uhM",
        "outputId": "2bf07ad0-7272-4181-e847-bced7bcd4bb6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing speaker id10016\n",
            "Processing speaker id10011\n",
            "Processing speaker id10004\n",
            "Processing speaker id10009\n",
            "Processing speaker id10017\n",
            "Found 691 files belonging to 395 classes.\n",
            "Using 553 files for training.\n",
            "Using 138 files for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "MFCC\n",
        "\n",
        "FFT (focus on low freq) ---> CNN (max pool in one direction)\n",
        "\n",
        "Is speaker unique in consonant or vowel?\n",
        "\n"
      ],
      "metadata": {
        "id": "9jlin8sbJRYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
        "    # Shortcut\n",
        "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
        "    for i in range(conv_num - 1):\n",
        "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "    x = keras.layers.Add()([x, s])\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
        "\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "    x = residual_block(inputs, 16, 2)\n",
        "    x = residual_block(x, 32, 2)\n",
        "    x = residual_block(x, 64, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "\n",
        "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "# model = build_model((SAMPLING_RATE//2, 1), len(class_names))\n",
        "model = build_model(N_MFCC, len(class_names))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model using Adam's default learning rate\n",
        "model.compile(\n",
        "    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Add callbacks:\n",
        "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
        "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
        "model_save_filename = \"model.h5\"\n",
        "\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "gMUzIPXQJRB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "xpMTXaQmJlRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fit()` is for training the model with the given inputs (and corresponding training labels).\n",
        "\n",
        "`evaluate()` is for evaluating the already trained model using the validation (or test) data and the corresponding labels. Returns the loss value and metrics values for the model.\n",
        "\n",
        "`predict()` is for the actual prediction. It generates output predictions for the input samples."
      ],
      "metadata": {
        "id": "VRecLUo_ELVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "33HkHl5aJnO2",
        "outputId": "46f5a1ca-3aff-4a72-b295-caf04529ce49"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-949a6a47e301>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopping_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdlcheckpoint_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input dimension 3 must have length of at least 26 but got: 13\n\t [[{{node mfccs_from_log_mel_spectrograms/dct/rfft}}]] [Op:IteratorGetNext]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "LF-Lf3hsLCZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(valid_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYufHcUMLD_C",
        "outputId": "9b9fef0d-c521-4df1-af65-beee89db82ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 4s 461ms/step - loss: 1.0957 - accuracy: 0.6087\n",
            "[1.0956804752349854, 0.6086956262588501]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(valid_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fsVZtGsEZ8z",
        "outputId": "e116d667-dc98-478e-a69e-d9126d4c3ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.32005882e-01 6.45957235e-03 4.20293927e-01 ... 1.85888614e-11\n",
            "  1.54312587e-12 3.42603237e-11]\n",
            " [6.73325002e-01 7.79852197e-02 1.06511056e-01 ... 3.76609955e-06\n",
            "  5.92110155e-07 3.57522913e-06]\n",
            " [7.45949507e-01 1.10497393e-01 7.59527981e-02 ... 6.52241965e-07\n",
            "  1.70138080e-07 1.31194531e-06]\n",
            " ...\n",
            " [4.66970950e-01 1.10281631e-01 3.97728413e-01 ... 1.51410729e-17\n",
            "  2.42138223e-18 1.37034261e-16]\n",
            " [3.45003270e-02 2.79879779e-01 5.97353326e-04 ... 1.14599116e-17\n",
            "  1.26591938e-18 9.09140645e-18]\n",
            " [1.51060745e-01 2.56404877e-01 8.70290771e-03 ... 2.08005835e-09\n",
            "  5.24520594e-10 1.46849777e-09]]\n"
          ]
        }
      ]
    }
  ]
}