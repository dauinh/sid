{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR2Rvs6NVAuS"
      },
      "source": [
        "# Speaker Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation & Imports"
      ],
      "metadata": {
        "id": "GUsmqYZIgdc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[VGGish Embedding Colab](https://colab.research.google.com/drive/1E3CaPAqCai9P9QhJ3WYPNCVmrJU4lAhF)"
      ],
      "metadata": {
        "id": "t8WW3Ke_gny_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U3U7NbTCXS6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2e23c2-7715-4b34-a17b-cbda3ba3f878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.8.0 in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.25.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.59.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-io==0.25.0 in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.25.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io==0.25.0) (0.25.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.23.5)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim) (1.4.0)\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 90080, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 90080 (delta 61), reused 100 (delta 50), pack-reused 89967\u001b[K\n",
            "Receiving objects: 100% (90080/90080), 606.63 MiB | 25.46 MiB/s, done.\n",
            "Resolving deltas: 100% (64896/64896), done.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorflow==2.8.0\n",
        "!pip3 install tensorflow-io==0.25.0\n",
        "!pip install numpy scipy\n",
        "!pip install resampy tensorflow\n",
        "!pip install tf_slim\n",
        "!rm -rf models\n",
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see where are in the kernel's file system.\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEWOcr68gjyZ",
        "outputId": "50e83c4d-87d4-47a4-cbd1-f3f01db5c030"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the VGGish model\n",
        "!curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
        "!curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiVWsKdzgmQs",
        "outputId": "db6229ea-9d8a-491d-a5b7-3f17b064a87c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  277M  100  277M    0     0  38.3M      0  0:00:07  0:00:07 --:--:-- 43.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 73020  100 73020    0     0   164k      0 --:--:-- --:--:-- --:--:--  164k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we got the model data.\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwfNMNu6g7RI",
        "outputId": "c0709f34-3494-42d2-9c38-e14788548dd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\t\t requirements.txt\t   vggish_model.ckpt\t  vggish_smoke_test.py\n",
            "mel_features.py  sample_data\t\t   vggish_params.py\t  vggish_train_demo.py\n",
            "models\t\t vggish_export_tfhub.py    vggish_pca_params.npz\n",
            "__pycache__\t vggish_inference_demo.py  vggish_postprocess.py\n",
            "README.md\t vggish_input.py\t   vggish_slim.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the location of the AudioSet source files\n",
        "!ls models/research/audioset/vggish"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnYEND0vgSkK",
        "outputId": "0456f89c-d8a2-40c0-db81-49db77646e1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mel_features.py   vggish_export_tfhub.py    vggish_params.py\t   vggish_smoke_test.py\n",
            "README.md\t  vggish_inference_demo.py  vggish_postprocess.py  vggish_train_demo.py\n",
            "requirements.txt  vggish_input.py\t    vggish_slim.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the source files to the current directory.\n",
        "!cp models/research/audioset/vggish/* ."
      ],
      "metadata": {
        "id": "a6BgFFjCg_7u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the source files got copied correctly.\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR6DF8CJhJri",
        "outputId": "468e517b-1d53-4e5d-b446-e2484269f6ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\t\t requirements.txt\t   vggish_model.ckpt\t  vggish_smoke_test.py\n",
            "mel_features.py  sample_data\t\t   vggish_params.py\t  vggish_train_demo.py\n",
            "models\t\t vggish_export_tfhub.py    vggish_pca_params.npz\n",
            "__pycache__\t vggish_inference_demo.py  vggish_postprocess.py\n",
            "README.md\t vggish_input.py\t   vggish_slim.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test, which also loads all the necessary functions.\n",
        "from vggish_smoke_test import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSrTZluHhMQ2",
        "outputId": "dd3a364d-4b15-4224-b417-73c0777e9773"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing your install of VGGish\n",
            "\n",
            "Resampling via resampy works!\n",
            "Log Mel Spectrogram example:  [[-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
            "  -4.60116305]\n",
            " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
            "  -4.60116305]\n",
            " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
            "  -4.60116305]\n",
            " ...\n",
            " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
            "  -4.60116305]\n",
            " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
            "  -4.60116305]\n",
            " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
            "  -4.60116305]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGGish embedding:  [-2.72986382e-01 -1.80314153e-01  5.19921184e-02 -1.43571526e-01\n",
            " -1.04673728e-01 -4.96598154e-01 -1.75267965e-01  4.23147976e-01\n",
            " -8.22126150e-01 -2.16801405e-01 -1.17509276e-01 -6.70077026e-01\n",
            "  1.43174574e-01 -1.44183934e-01  8.73491913e-03 -8.71972442e-02\n",
            " -1.84393525e-01  5.96655607e-01 -3.43809605e-01 -5.79104424e-02\n",
            " -1.65071294e-01  4.22911644e-02 -2.55293399e-01 -2.36356765e-01\n",
            "  1.80295616e-01  3.02612185e-01  1.08356833e-01 -4.48398024e-01\n",
            "  1.22757629e-01 -2.99955189e-01 -5.55934191e-01  5.05966544e-01\n",
            "  2.05210358e-01  8.87591839e-01  9.03702497e-01 -2.10566416e-01\n",
            " -3.27462405e-02  1.38691410e-01 -2.27416530e-01  1.14804000e-01\n",
            "  5.95410109e-01 -4.76971269e-01  2.28232622e-01  1.54627025e-01\n",
            "  1.64934218e-01  7.19252825e-01  1.24101830e+00  5.61996222e-01\n",
            "  2.73531973e-01  3.09788287e-02  2.10977703e-01 -6.09551668e-01\n",
            " -3.15282375e-01  1.76392645e-01 -8.96190405e-02 -4.26822364e-01\n",
            "  3.12993884e-01 -1.56592295e-01  3.31673503e-01  1.29436389e-01\n",
            "  1.66024208e-01  3.01903039e-02 -1.54465199e-01 -4.29332554e-01\n",
            " -2.68703818e-01 -1.58071086e-01  4.00485486e-01 -2.55945086e-01\n",
            " -2.66429391e-02  8.16181302e-03  2.98492879e-01  3.48756194e-01\n",
            " -1.07143626e-01  8.88779089e-02  1.26810491e-01 -3.34817201e-01\n",
            " -2.55428016e-01  5.07779241e-01  3.97584617e-01  1.78759634e-01\n",
            " -8.04521963e-02  4.84320521e-02 -2.01262981e-01 -2.97957748e-01\n",
            "  3.66831303e-01  4.56224501e-01  5.37960529e-01 -2.00488269e-02\n",
            " -6.24543577e-02  4.15623039e-01 -1.88741475e-01 -5.36903143e-01\n",
            " -1.78362012e-01  3.81366849e-01  3.96645039e-01  3.21936429e-01\n",
            " -4.26683240e-02 -1.41018063e-01 -4.53833699e-01 -1.07017279e-01\n",
            " -2.21892655e-01  3.51183444e-01 -2.58386552e-01  3.31110060e-01\n",
            " -7.28939176e-01 -2.55487382e-01  3.56361002e-01 -3.16188633e-01\n",
            "  3.12793672e-01  1.23501822e-01 -1.83649734e-02 -3.99395853e-01\n",
            " -5.13507247e-01 -2.74227202e-01 -2.68650651e-01  2.24091530e-01\n",
            "  1.09625012e-01  1.30929738e-01 -1.25994891e-01 -1.92615181e-01\n",
            "  1.83567405e-04  2.04150438e-01 -1.03096753e-01  2.93378532e-02\n",
            " -3.38305712e-01 -2.25749940e-01 -2.46723339e-01 -1.20763183e-01]\n",
            "embedding mean/stddev 0.00065699156 0.34301957\n",
            "Postprocessed VGGish embedding:  [160  53 124 132 154 120 119 105 155 173 129  69 149  93  59   0  52  97\n",
            " 157 144 153 194 251 108  48 174 131 190 195  79  59  60 169  93 167 247\n",
            "  28  75 255  56 134 169 234 137 232 100  19  80 162 255   0 255 101   0\n",
            " 222 252  79 211  64  88 248   0   0 255 246  62  81 255   0 159  22 168\n",
            "  70 255  99 135 204 192 255 150   0   0 255 255  67 235  55 255  69   0\n",
            "   0  17 241  44 255 224   0 255  40   0 255   0 211 252  62   0  28 218\n",
            " 112   0 255   0  81  67 153   0 255   0 129 229  53 255  55 101   0 255\n",
            "   0 255]\n",
            "postproc embedding mean/stddev 126.359375 89.33878063086252\n",
            "\n",
            "Looks Good To Me!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary imports"
      ],
      "metadata": {
        "id": "uL3EdaUOhGUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwG9JJB6U3OF",
        "outputId": "ca1eaa62-38d8-43ad-af3a-d191350470dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n",
            "TensorFlow IO version: 0.25.0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"TensorFlow IO version:\", tfio.__version__)\n",
        "print(tf.executing_eagerly())\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x6YLgMwXYmD",
        "outputId": "e5fccf6b-56db-41af-d0ce-2bdaafdb2236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ROOT_DIR='/content/drive/MyDrive/College/Research/Linh_2023_Research'\n",
        "\n",
        "DATASET_PATH=ROOT_DIR+'/test_data/vox'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsF8O-L0VRZA"
      },
      "source": [
        "## Dataset preparation\n",
        "[Keras Speaker Recognition](https://keras.io/examples/audio/speaker_recognition_using_cnn/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLING_RATE = 16000\n",
        "BATCH_SIZE = 128\n",
        "SHUFFLE_SEED = 43\n",
        "TRAIN_VALID_SPLIT = 0.2\n",
        "EPOCHS = 100\n",
        "\n",
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n",
        "    return audio"
      ],
      "metadata": {
        "id": "DZ7nq7DR7FeQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FFT & MFCC Pre-processing\n"
      ],
      "metadata": {
        "id": "3Rfi3sN3nrm_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CXc8U7QY8Jwn"
      },
      "outputs": [],
      "source": [
        "N_MFCC = 13\n",
        "\n",
        "def audio_to_fft(audio):\n",
        "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
        "    # we need to squeeze the dimensions and then expand them again\n",
        "    # after FFT\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    fft = tf.signal.fft(\n",
        "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
        "    )\n",
        "    fft = tf.expand_dims(fft, axis=-1)\n",
        "\n",
        "    # Return the absolute value of the first half of the FFT\n",
        "    # which represents the positive frequencies\n",
        "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])\n",
        "\n",
        "def audio_to_mfcc(audio):\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    # Convert the audio to MFCC\n",
        "    stfts = tf.signal.stft(audio, frame_length=1024, frame_step=256, fft_length=1024)\n",
        "    spectrograms = tf.abs(stfts)\n",
        "\n",
        "    # Warp the linear scale spectrograms into the mel-scale\n",
        "    num_spectrogram_bins = stfts.shape[-1]\n",
        "    lower_edge_hertz, upper_edge_hertz = 80.0, 7600.0\n",
        "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "        N_MFCC, num_spectrogram_bins, SAMPLING_RATE, lower_edge_hertz, upper_edge_hertz)\n",
        "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
        "    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "    # Compute a stabilized log to get log-magnitude mel-scale spectrograms\n",
        "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
        "\n",
        "    # Compute MFCCs from log_mel_spectrograms and take the first N_MFCC\n",
        "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :N_MFCC]\n",
        "    # print(mfccs)\n",
        "\n",
        "    return mfccs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGGish Embeddings"
      ],
      "metadata": {
        "id": "tnSx_lEdnktP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vggish_slim\n",
        "import vggish_params\n",
        "import vggish_input\n",
        "\n",
        "\n",
        "def load_vggish_slim_checkpoint(checkpoint_path):\n",
        "    \"\"\"Loads a pre-trained VGGish-compatible checkpoint.\n",
        "\n",
        "    This function can be used as an initialization function (referred to as\n",
        "    init_fn in TensorFlow documentation) which is called after\n",
        "    initializing all variables. When used as an init_fn, this will load\n",
        "    a pre-trained checkpoint that is compatible with the VGGish model\n",
        "    definition. Only variables defined by VGGish will be loaded.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path: path to a file containing a checkpoint that is\n",
        "          compatible with the VGGish model definition.\n",
        "    \"\"\"\n",
        "    # Get the list of names of all VGGish variables that exist in\n",
        "    # the checkpoint (i.e., all inference-mode VGGish variables).\n",
        "    vggish_slim.define_vggish_slim(training=False)\n",
        "    vggish_var_names = [v.name for v in tf.compat.v1.global_variables()]\n",
        "\n",
        "    # Get the list of all currently existing variables that match\n",
        "    # the list of variable names we just computed.\n",
        "    vggish_vars = [v for v in tf.compat.v1.global_variables() if v.name in vggish_var_names]\n",
        "\n",
        "    # Use a Saver to restore just the variables selected above.\n",
        "    saver = tf.train.Saver(vggish_vars, name='vggish_load_pretrained', save_relative_paths=True)\n",
        "    saver.restore(checkpoint_path)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def create_vggish_network(hop_size=0.96):   # Hop size is in seconds.\n",
        "    \"\"\"Define VGGish model, load the checkpoint, and return a dictionary that points\n",
        "    to the different tensors defined by the model.\n",
        "    \"\"\"\n",
        "    assert not tf.executing_eagerly()\n",
        "    vggish_slim.define_vggish_slim()\n",
        "    checkpoint_path = 'vggish_model.ckpt'\n",
        "    vggish_params.EXAMPLE_HOP_SECONDS = hop_size\n",
        "\n",
        "    g = tf.Graph()\n",
        "    with g.as_default():\n",
        "        load_vggish_slim_checkpoint(checkpoint_path)\n",
        "\n",
        "        features_tensor = g.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
        "        embedding_tensor = g.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
        "\n",
        "        layers = {'conv1': 'vggish/conv1/Relu:0',\n",
        "                'pool1': 'vggish/pool1/MaxPool:0',\n",
        "                'conv2': 'vggish/conv2/Relu:0',\n",
        "                'pool2': 'vggish/pool2/MaxPool:0',\n",
        "                'conv3': 'vggish/conv3/conv3_2/Relu:0',\n",
        "                'pool3': 'vggish/pool3/MaxPool:0',\n",
        "                'conv4': 'vggish/conv4/conv4_2/Relu:0',\n",
        "                'pool4': 'vggish/pool4/MaxPool:0',\n",
        "                'fc1': 'vggish/fc1/fc1_2/Relu:0',\n",
        "                'embedding': 'vggish/embedding:0',\n",
        "                'features': 'vggish/input_features:0',\n",
        "                }\n",
        "\n",
        "        for k in layers:\n",
        "            layers[k] = g.get_tensor_by_name(layers[k])\n",
        "\n",
        "        return {'features': features_tensor,\n",
        "                'embedding': embedding_tensor,\n",
        "                'layers': layers,\n",
        "                'graph': g\n",
        "            }\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def embeddings_from_vggish(vgg, x, sr=SAMPLING_RATE):\n",
        "    \"\"\"Run the VGGish model, starting with a sound (x) at sample rate\n",
        "    (sr). Return a dictionary of embeddings from the different layers\n",
        "    of the model.\"\"\"\n",
        "    assert not tf.executing_eagerly()\n",
        "    input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "\n",
        "    layer_names = vgg['layers'].keys()\n",
        "    tensors = [vgg['layers'][k] for k in layer_names]\n",
        "\n",
        "    with vgg['graph'].as_default():\n",
        "        with tf.compat.v1.Session() as session:\n",
        "            session.run(tf.compat.v1.global_variables_initializer())\n",
        "            input_tensor = vgg['features']\n",
        "            feed_dict = {input_tensor: input_batch}\n",
        "            results = session.run(tensors, feed_dict=feed_dict)\n",
        "\n",
        "    resdict = {}\n",
        "    for i, k in enumerate(layer_names):\n",
        "        resdict[k] = results[i]\n",
        "\n",
        "    return resdict"
      ],
      "metadata": {
        "id": "fA839fO-EsU_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file_path = DATASET_PATH + '/id10004/BOAd7pybyZw00003.wav'\n",
        "x = path_to_audio(audio_file_path)\n",
        "print(type(x))\n",
        "print(tf.executing_eagerly())"
      ],
      "metadata": {
        "id": "y-K9OKp_n9zn",
        "outputId": "a33c0f4a-ee95-4171-e5f5-750e15b553a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def audio_to_embeddings(audio):\n",
        "    assert not tf.executing_eagerly()\n",
        "    print('inner', tf.executing_eagerly())\n",
        "    vgg = create_vggish_network(0.01)\n",
        "    # resdict = embeddings_from_vggish(vgg, audio)\n",
        "\n",
        "    # print(resdict['embedding'].shape)\n",
        "    # print(type(resdict['embedding']))\n",
        "    # return resdict['embedding']\n",
        "print('outter', tf.executing_eagerly())\n",
        "audio_to_embeddings(x.numpy())\n",
        "print(tf.executing_eagerly())"
      ],
      "metadata": {
        "id": "A7VUDltMHILz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process data"
      ],
      "metadata": {
        "id": "m8UD9c3qoNA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSzqjnpz4uhM"
      },
      "outputs": [],
      "source": [
        "N_CLASS = 5\n",
        "class_names = os.listdir(DATASET_PATH)\n",
        "random.shuffle(class_names)\n",
        "audio_paths = []\n",
        "labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    if label > N_CLASS - 1: break\n",
        "    print(\"Processing speaker {}\".format(name,))\n",
        "    dir_path = Path(DATASET_PATH) / name\n",
        "    speaker_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    audio_paths += speaker_sample_paths\n",
        "    labels += [label] * len(speaker_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
        ")\n",
        "\n",
        "# Shuffle\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(audio_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Split into training and validation\n",
        "num_val_samples = int(TRAIN_VALID_SPLIT * len(audio_paths))\n",
        "print(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\n",
        "train_audio_paths = audio_paths[:-num_val_samples]\n",
        "train_labels = labels[:-num_val_samples]\n",
        "\n",
        "print(\"Using {} files for validation.\".format(num_val_samples))\n",
        "valid_audio_paths = audio_paths[-num_val_samples:]\n",
        "valid_labels = labels[-num_val_samples:]\n",
        "\n",
        "# Create 2 datasets, one for training and the other for validation\n",
        "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
        "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
        "\n",
        "# Transform audio wave to the frequency domain using `audio_to_mfcc`\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (audio_to_mfcc(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "valid_ds = valid_ds.map(\n",
        "    lambda x, y: (audio_to_mfcc(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frTFswK4CGRr"
      },
      "outputs": [],
      "source": [
        "# for i, data in enumerate(train_ds):\n",
        "#     if i > 2: break\n",
        "#     x, y = data\n",
        "#     # Extract the chosen sample\n",
        "#     selected_sample_np = x[i].numpy()\n",
        "\n",
        "#     # Display the MFCC for the selected sample\n",
        "#     plt.imshow(selected_sample_np, cmap='viridis', origin='lower', aspect='auto')\n",
        "#     plt.title(f'MFCC for Sample {i}')\n",
        "#     plt.xlabel('MFCC Coefficient')\n",
        "#     plt.ylabel('Time Step')\n",
        "#     plt.colorbar(label='Magnitude')\n",
        "#     plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jlin8sbJRYj"
      },
      "source": [
        "## Model\n",
        "\n",
        "MFCC\n",
        "\n",
        "FFT (focus on low freq) ---> CNN (max pool in one direction)\n",
        "\n",
        "Is speaker unique in consonant or vowel?\n",
        "\n",
        "To try: Cifar, Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple ResNet"
      ],
      "metadata": {
        "id": "iyhOcSlQeYdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
        "    # Shortcut\n",
        "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
        "    for i in range(conv_num - 1):\n",
        "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "    x = keras.layers.Add()([x, s])\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
        "\n",
        "\n",
        "def simple_resnet(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "    x = residual_block(inputs, 16, 2)\n",
        "    x = residual_block(x, 32, 2)\n",
        "    x = residual_block(x, 64, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    # x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    return keras.models.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "imt11oYweVzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnFLlceDEwmQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# model = simple_resnet((SAMPLING_RATE//2, 1), N_CLASS)\n",
        "model = simple_resnet((59, N_MFCC), N_CLASS)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model using Adam's default learning rate\n",
        "model.compile(\n",
        "    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Add callbacks:\n",
        "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
        "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
        "model_save_filename = \"model.h5\"\n",
        "\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpMTXaQmJlRo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRecLUo_ELVz"
      },
      "source": [
        "`fit()` is for training the model with the given inputs (and corresponding training labels).\n",
        "\n",
        "`evaluate()` is for evaluating the already trained model using the validation (or test) data and the corresponding labels. Returns the loss value and metrics values for the model.\n",
        "\n",
        "`predict()` is for the actual prediction. It generates output predictions for the input samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33HkHl5aJnO2"
      },
      "outputs": [],
      "source": [
        "# Define the Keras TensorBoard callback\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[earlystopping_cb, mdlcheckpoint_cb, tensorboard_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUHcoTI4j1en"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF-Lf3hsLCZB"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYufHcUMLD_C"
      },
      "outputs": [],
      "source": [
        "print(model.evaluate(valid_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fsVZtGsEZ8z"
      },
      "outputs": [],
      "source": [
        "print(model.predict(valid_ds))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOClfg9RRP92dYEh49S4S97"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}